
platform :ios, ‘8.0’

target ‘AVFoundationTwo’ do
use_frameworks!

    pod 'AFNetworking'
    pod 'YYModel'
    pod 'Masonry'
    pod 'MJRefresh'
    pod 'SDWebImage','4.4.6'
    pod 'MBProgressHUD',    '1.1.0'
    pod 'TYPagerController'


end

#功能实现
#1. 几个相关的类
#
#
#AVCaptureSession
#媒体（音、视频）捕获会话，负责把捕获的音视频数据输出到输出设备中。一个AVCaptureSession可以有多个输入输出。 AVCaptureSession是AVFoundation捕捉类的中心枢纽，在视频捕获时,客户端可以实例化AVCaptureSession并添加适当的AVCaptureInputs、AVCaptureDeviceInput和输出，比如AVCaptureMovieFileOutput。通过[AVCaptureSession startRunning]开始数据流从输入到输出,和[AVCaptureSession stopRunning]停止输出输入的流动。客户端可以通过设置sessionPreset属性定制录制质量水平或输出的比特率。
#
#AVCaptureDevice
#输入设备，包括麦克风、摄像头，通过该对象可以设置物理设备的一些属性（例如相机聚焦、白平衡等）。
#
#AVCaptureDeviceInput
#设备输入数据管理对象，可以根据AVCaptureDevice创建对应AVCaptureDeviceInput对象，该对象将会被添加到AVCaptureSession中管理。
#
#AVCaptureOutput
#输出数据管理对象，用于接收各类输出数据，通常使用对应的子类AVCaptureAudioDataOutput、AVCaptureStillImageOutput、AVCaptureVideoDataOutput、AVCaptureFileOutput，该对象将会被添加到AVCaptureSession中管理。注意：前面几个对象的输出数据都是NSData类型，而AVCaptureFileOutput代表数据以文件形式输出，类似的，AVCcaptureFileOutput也不会直接创建使用，通常会使用其子类：AVCaptureAudioFileOutput、AVCaptureMovieFileOutput。当把一个输入或者输出添加到AVCaptureSession之后AVCaptureSession就会在所有相符的输入、输出设备之间建立连接（AVCaptionConnection）`。
#
#AVCaptureVideoPreviewLayer
#相机拍摄预览图层，是CALayer的子类，使用该对象可以实时查看拍照或视频录制效果，创建该对象需要指定对应的AVCaptureSession对象。
#
#2. 视频录制的步骤
#
#创建AVCaptureSession对象。
#使用AVCaptureDevice的静态方法获得需要使用的设备，例如拍照和录像就需要获得摄像头设备，录音就要获得麦克风设备。
#利用输入设备AVCaptureDevice初始化AVCaptureDeviceInput对象。
#初始化输出数据管理对象，如果要拍照就初始化AVCaptureStillImageOutput对象；如果拍摄视频就初始化AVCaptureMovieFileOutput对象。
#将数据输入对象AVCaptureDeviceInput、数据输出对象AVCaptureOutput添加到媒体会话管理对象AVCaptureSession中。
#创建视频预览图层AVCaptureVideoPreviewLayer并指定媒体会话，添加图层到显示容器中，调用AVCaptureSession的startRuning方法开始捕获。
#将捕获的音频或视频数据输出到指定文件。


